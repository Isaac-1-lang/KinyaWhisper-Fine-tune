{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63427f25",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "# \"\"\"\n",
    "# test_downloaded_audio.py\n",
    "\n",
    "# Tests the KinyaWhisper model on the downloaded audio files from download_kinya_audio.py.\n",
    "# Compares model predictions with ground truth transcripts and calculates accuracy metrics.\n",
    "# \"\"\"\n",
    "\n",
    "# import csv\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "# import torchaudio\n",
    "# import torch\n",
    "# from jiwer import wer, cer\n",
    "\n",
    "# # ====== Configuration ======\n",
    "# audio_dir = \"data/audio\"\n",
    "# csv_file = \"audio_transcripts.csv\"\n",
    "# output_file = \"test_results.csv\"\n",
    "# model_name = \"benax-rw/KinyaWhisper\"  # Use Hugging Face model\n",
    "\n",
    "# # ====== Load model and processor ======\n",
    "# print(\"üîÑ Loading KinyaWhisper model...\")\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "# processor = WhisperProcessor.from_pretrained(model_name)\n",
    "# model.eval()\n",
    "# print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# # ====== Load ground truth transcripts from CSV ======\n",
    "# print(f\"\\nüìñ Loading transcripts from {csv_file}...\")\n",
    "# ground_truth = {}\n",
    "# with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     reader = csv.DictReader(f)\n",
    "#     for row in reader:\n",
    "#         ground_truth[row[\"filename\"]] = row[\"transcript\"]\n",
    "\n",
    "# print(f\"‚úÖ Loaded {len(ground_truth)} transcripts\")\n",
    "\n",
    "# # ====== Process each audio file ======\n",
    "# results = []\n",
    "# predictions = []\n",
    "# references = []\n",
    "\n",
    "# print(f\"\\nüé§ Transcribing audio files from {audio_dir}...\")\n",
    "\n",
    "# for i, (filename, true_transcript) in enumerate(ground_truth.items(), 1):\n",
    "#     audio_path = Path(audio_dir) / filename\n",
    "\n",
    "#     if not audio_path.exists():\n",
    "#         print(f\"‚ö†Ô∏è  Skipping {filename} (file not found)\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         # Load and preprocess audio\n",
    "#         waveform, sample_rate = torchaudio.load(str(audio_path))\n",
    "\n",
    "#         # Convert stereo to mono if needed\n",
    "#         if waveform.shape[0] > 1:\n",
    "#             waveform = waveform.mean(dim=0)\n",
    "#         else:\n",
    "#             waveform = waveform.squeeze()\n",
    "\n",
    "#         # Prepare input\n",
    "#         inputs = processor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "\n",
    "#         # Generate transcription\n",
    "#         with torch.no_grad():\n",
    "#             predicted_ids = model.generate(inputs[\"input_features\"])\n",
    "\n",
    "#         # Decode transcription\n",
    "#         predicted_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "#         # Store results\n",
    "#         results.append({\n",
    "#             \"filename\": filename,\n",
    "#             \"ground_truth\": true_transcript,\n",
    "#             \"prediction\": predicted_text,\n",
    "#             \"match\": true_transcript.strip().lower() == predicted_text.strip().lower()\n",
    "#         })\n",
    "\n",
    "#         predictions.append(predicted_text)\n",
    "#         references.append(true_transcript)\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"  Processed {i}/{len(ground_truth)} files...\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error processing {filename}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# print(f\"‚úÖ Processed {len(results)} audio files!\")\n",
    "\n",
    "# # ====== Calculate metrics ======\n",
    "# print(\"\\nüìä Calculating accuracy metrics...\")\n",
    "\n",
    "# # Calculate Word Error Rate (WER) and Character Error Rate (CER)\n",
    "# if predictions and references:\n",
    "#     wer_score = wer(references, predictions)\n",
    "#     cer_score = cer(references, predictions)\n",
    "\n",
    "#     # Calculate exact match accuracy\n",
    "#     exact_matches = sum(1 for r in results if r[\"match\"])\n",
    "#     accuracy = exact_matches / len(results) * 100 if results else 0\n",
    "\n",
    "#     print(f\"\\nüìà Results:\")\n",
    "#     print(f\"   Word Error Rate (WER): {wer_score:.2%}\")\n",
    "#     print(f\"   Character Error Rate (CER): {cer_score:.2%}\")\n",
    "#     print(f\"   Exact Match Accuracy: {accuracy:.2f}% ({exact_matches}/{len(results)})\n",
    "\n",
    "# # ====== Save results to CSV ======\n",
    "# print(f\"\\nüíæ Saving results to {output_file}...\")\n",
    "# with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     fieldnames = [\"filename\", \"ground_truth\", \"prediction\", \"match\"]\n",
    "#     writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(results)\n",
    "\n",
    "# print(f\"‚úÖ Results saved to {output_file}\")\n",
    "\n",
    "# # ====== Print sample results ======\n",
    "# print(f\"\\nüìù Sample Results (first 5):\")\n",
    "# print(\"-\" * 80)\n",
    "# for i, result in enumerate(results[:5], 1):\n",
    "#     print(f\"\\n{i}. {result['filename']}\")\n",
    "#     print(f\"   Ground Truth: {result['ground_truth']}\")\n",
    "#     print(f\"   Prediction:   {result['prediction']}\")\n",
    "#     print(f\"   Match: {'‚úÖ' if result['match'] else '‚ùå'}\")\n",
    "\n",
    "# print(\"\\nüéâ Testing complete!\")\n",
    "\n",
    "\n",
    "# from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "# import torchaudio\n",
    "\n",
    "# # Load kinya whisper-small model and processor from Hugging Face\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(\"benax-rw/KinyaWhisper\")\n",
    "# processor = WhisperProcessor.from_pretrained(\"benax-rw/KinyaWhisper\")\n",
    "\n",
    "# # Load and preprocess audio\n",
    "# waveform, sample_rate = torchaudio.load(\"data/audio/sample_1.wav\")\n",
    "# inputs = processor(waveform.squeeze(), sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate prediction\n",
    "# predicted_ids = model.generate(inputs[\"input_features\"])\n",
    "# transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "# print(\"üó£Ô∏è Transcription:\", transcription)\n",
    "\n",
    "!pip install torchcodec\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np # Import numpy\n",
    "\n",
    "MODEL_NAME = \"mbazaNLP/Whisper-Small-Kinyarwanda\"\n",
    "\n",
    "# Load model + processor\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "# Load audio\n",
    "waveform, sample_rate = torchaudio.load(\"./sample_3.wav\")\n",
    "\n",
    "# Convert to mono\n",
    "if waveform.shape[0] > 1:\n",
    "    waveform = waveform.mean(dim=0)\n",
    "\n",
    "# Resample to 16kHz (VERY IMPORTANT)\n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "    waveform = resampler(waveform)\n",
    "    sample_rate = 16000\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array of float32\n",
    "# This ensures the feature extractor receives data in a highly compatible format.\n",
    "audio_input = waveform.cpu().numpy().astype(np.float32)\n",
    "\n",
    "# Prepare input\n",
    "inputs = processor(\n",
    "    audio_input,\n",
    "    sampling_rate=sample_rate,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Force Kinyarwanda transcription\n",
    "# The processor's tokenizer does not natively support 'rw' as a prompt ID.\n",
    "# For fine-tuned models, it's often best to let the model determine the language.\n",
    "# Commenting out or removing this line will allow the model to transcribe directly.\n",
    "# forced_ids = processor.get_decoder_prompt_ids(\n",
    "#     language=\"rw\",\n",
    "#     task=\"transcribe\"\n",
    "# )\n",
    "\n",
    "# Generate\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(\n",
    "        inputs[\"input_features\"],\n",
    "        # Remove forced_decoder_ids as 'rw' is not supported by the base tokenizer's prompt IDs.\n",
    "        # forced_decoder_ids=forced_ids\n",
    "    )\n",
    "\n",
    "# Decode\n",
    "transcription = processor.batch_decode(\n",
    "    predicted_ids,\n",
    "    skip_special_tokens=True\n",
    ")[0]\n",
    "\n",
    "print(\"üó£Ô∏è Transcription:\", transcription)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
